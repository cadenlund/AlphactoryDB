{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fc3e72-ea3e-4212-b7cb-45a51aaf1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 #Amazon AWS Python SDK\n",
    "from botocore.config import Config #Config for SDK\n",
    "from dotenv import load_dotenv # Load .ENV file containing protected information\n",
    "import os # Ability to manage and access neigboring files \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8eb67cc-ad0d-4c5f-a2d7-8a340f882fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the environment variables available to python from the .env file\n",
    "load_dotenv()\n",
    "# Load the environment variables into python variables\n",
    "ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "POLYGON_KEY = os.getenv(\"POLYGON_API_KEYS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2e2e56-7aff-4b0c-a5fd-811223183779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a session using the AWS keys\n",
    "session = boto3.Session( # Session object used to configure users and environment control\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1cc006-48ed-437a-b387-e6207ec2c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client with session and speficy the endpoint (where the data is located)\n",
    "s3 = session.client(\n",
    "    's3', # Connecting to the S3 (Simple Storage Service) specifically (can connect to any aws service here)\n",
    "    endpoint_url='https://files.polygon.io', # Base url for the service you want to access\n",
    "    config=Config(signature_version='s3v4'), # Ensures client is using AWS signature Version 4 protocol by prohibiting api requests unless supplied with\n",
    "                                             # a secret key. Used for hashsing\n",
    ")\n",
    "# The previous code is everything needed to accesss the S3 flatfiles, from here you can use commands like list objects or get objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32059842-ab37-482b-9da9-198a82bebde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a paginator for listing objects\n",
    "paginator = s3.get_paginator('list_objects_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d92d8a-8d2b-43e2-94fd-c4e8f14fc85e",
   "metadata": {},
   "source": [
    "## üåê Understanding Requests and Paginators in S3 (Conceptual Overview)\n",
    "\n",
    "### üì§ What is a Request?\n",
    "\n",
    "A **request** is a single operation sent from your client (e.g., Python code) to a server (e.g., AWS S3 or Polygon‚Äôs S3-compatible endpoint). For example, when you ask to list files in a folder-like structure in a bucket, that is a request.\n",
    "\n",
    "S3‚Äôs `list_objects_v2` request returns a maximum of 1000 objects (files) at a time. If more files exist, it only returns the first \"page\" and indicates that more data is available.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ What is a Paginator?\n",
    "\n",
    "A **paginator** is a built-in tool provided by `boto3` that automatically handles repeated requests when the response is paginated. \n",
    "\n",
    "Instead of manually tracking continuation tokens and sending new requests, the paginator transparently performs this for you. It lets you iterate over all the data as if it were returned in one big response.\n",
    "\n",
    "---\n",
    "\n",
    "### ü™£ S3 Paginators Specifically\n",
    "\n",
    "S3 paginators are used to retrieve more than 1000 files (objects) from a bucket. You create a paginator specifically for the `list_objects_v2` operation, which is the improved version of the original S3 listing API.\n",
    "\n",
    "The paginator handles:\n",
    "- Sending the first request\n",
    "- Detecting if the result is truncated (chopped off)\n",
    "- Sending follow-up requests with the continuation token\n",
    "- Returning each full page of results one after the other\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Key Parameters Used with S3 Paginators\n",
    "\n",
    "- **Bucket**: The name of the S3 bucket you are querying.\n",
    "- **Prefix**: A folder-like path that limits the results to objects that begin with that string.\n",
    "- **Delimiter** (optional): Used to group files as if they were in folders (commonly set to `/`).\n",
    "- **PaginationConfig** (optional): Allows advanced control, like page size or starting from a specific point.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary\n",
    "\n",
    "- A **request** retrieves a single chunk of data from S3.\n",
    "- A **paginator** automates multiple requests so you can work with large datasets easily.\n",
    "- S3 paginators are essential when listing more than 1000 files in a bucket or folder-like structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c6eb49-11d7-47bb-b084-4217e0f49da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygon import RESTClient\n",
    "from polygon.rest.models import (\n",
    "    TickerSnapshot,\n",
    "    Agg,\n",
    ") #Python libraries for polygon\n",
    "\n",
    "client = RESTClient(POLYGON_KEY) # Activating Polygon REST API\n",
    "\n",
    "snapshot = client.get_snapshot_all(\n",
    "\t\"stocks\",\n",
    "\t) # Returns a snapshot of all stocks daily activities, includes over 10000 tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a87b6d-38e7-4336-a2de-b01200e2300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(snapshot) # Make json object a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c73171-f76a-4c2c-bfaa-41c627450435",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = pd.json_normalize(df['day']) # Turn json dict into dataframe\n",
    "day_df = day_df[['volume', 'vwap']]  # Only keep the ones you care about (Volume and VWAP)\n",
    "final_df = pd.concat([df['ticker'], day_df], axis=1) # Concatenate the ticker onto the rows on the left side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210f04d7-ef97-4403-b6b0-d4b318fa143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['dollar_volume'] = df['day'].apply(lambda x: x['volume'] * x['vwap']) # Lambda function to create dollar volume\n",
    "final_df = final_df.sort_values(by='dollar_volume', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ab0bc2-14a8-4c45-ba0e-27406728e8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "ticker_list = list(final_df['ticker'][:500])\n",
    "print(len(ticker_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d7b012-3172-4fec-89bc-6cef550859ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker           0\n",
       "volume           0\n",
       "vwap             0\n",
       "dollar_volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isnull().sum() # Print null values per column to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e98c3fc-4cb9-4963-8599-a44feb6bbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy example\n",
    "# Specify the bucket name\n",
    "bucket_name = 'flatfiles'\n",
    "\n",
    "# Specify the S3 object key name\n",
    "object_key = 'us_stocks_sip/minute_aggs_v1/2025/03/2025-03-20.csv.gz'\n",
    "\n",
    "# Specify the local file name and path to save the downloaded file\n",
    "# This splits the object_key string by '/' and takes the last segment as the file name\n",
    "local_file_name = object_key.split('/')[-1]\n",
    "\n",
    "# This constructs the full local file path\n",
    "local_file_path = './' + local_file_name\n",
    "\n",
    "# Download the file\n",
    "s3.download_file(bucket_name, object_key, local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb655b2-8915-48d5-849e-60741d5013ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>window_start</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>11905</td>\n",
       "      <td>121.720</td>\n",
       "      <td>122.055</td>\n",
       "      <td>122.055</td>\n",
       "      <td>121.720</td>\n",
       "      <td>1742477400000000000</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1268</td>\n",
       "      <td>122.075</td>\n",
       "      <td>122.075</td>\n",
       "      <td>122.075</td>\n",
       "      <td>122.075</td>\n",
       "      <td>1742477460000000000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>565</td>\n",
       "      <td>122.075</td>\n",
       "      <td>122.075</td>\n",
       "      <td>122.075</td>\n",
       "      <td>122.075</td>\n",
       "      <td>1742477520000000000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>8163</td>\n",
       "      <td>122.075</td>\n",
       "      <td>122.070</td>\n",
       "      <td>122.080</td>\n",
       "      <td>121.440</td>\n",
       "      <td>1742477580000000000</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>4209</td>\n",
       "      <td>122.065</td>\n",
       "      <td>120.810</td>\n",
       "      <td>122.065</td>\n",
       "      <td>120.810</td>\n",
       "      <td>1742477640000000000</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  volume     open    close     high      low         window_start  \\\n",
       "0      A   11905  121.720  122.055  122.055  121.720  1742477400000000000   \n",
       "1      A    1268  122.075  122.075  122.075  122.075  1742477460000000000   \n",
       "2      A     565  122.075  122.075  122.075  122.075  1742477520000000000   \n",
       "3      A    8163  122.075  122.070  122.080  121.440  1742477580000000000   \n",
       "4      A    4209  122.065  120.810  122.065  120.810  1742477640000000000   \n",
       "\n",
       "   transactions  \n",
       "0            36  \n",
       "1            17  \n",
       "2            16  \n",
       "3            81  \n",
       "4           117  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you've already downloaded the file\n",
    "df = pd.read_csv(local_file_path, compression='gzip')\n",
    "\n",
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1420216-63a5-4d76-9472-6d62310f1eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n"
     ]
    }
   ],
   "source": [
    "#Now I will create a dataframe where the tickers only match the ones in the ticker list, we will filter them out and check if the \n",
    "# minute agg bars amount is the same across tickers. \n",
    "\n",
    "filtered_df = df[df['ticker'].isin(ticker_list)]\n",
    "print(len(filtered_df['ticker'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "822f0f2f-6cfb-4b6c-8a33-05c699dc38d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing tickers:\n",
      "CRWV\n",
      "NMAX\n"
     ]
    }
   ],
   "source": [
    "# Now I will print the missing tickers that did not get imported but was in the ticker list\n",
    "\n",
    "filtered_tickers = set(filtered_df['ticker'].unique())\n",
    "expected_tickers = set(ticker_list)\n",
    "\n",
    "missing = expected_tickers - filtered_tickers\n",
    "\n",
    "print(\"Missing tickers:\")\n",
    "for ticker in sorted(missing):\n",
    "    print(ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af34602-fb69-4a34-9d95-6a26c17ad53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
