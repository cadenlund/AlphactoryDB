{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ee0566-836f-4bc6-ac02-8f4df0d49956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 #Amazon AWS Python SDK\n",
    "from botocore.config import Config #Config for SDK\n",
    "from dotenv import load_dotenv # Load .ENV file containing protected information\n",
    "import os # Ability to manage and access neigboring files \n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e998b971-639b-402f-924c-e443f70bdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the environment variables available to python from the .env file\n",
    "load_dotenv()\n",
    "# Load the environment variables into python variables\n",
    "ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc09f94-70d6-44df-aa42-8a8eddbae7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a session using the AWS keys\n",
    "session = boto3.Session( # Session object used to configure users and environment control\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf6ea58-5ad6-406e-8293-1e95537d8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client with session and speficy the endpoint (where the data is located)\n",
    "s3 = session.client(\n",
    "    's3', # Connecting to the S3 (Simple Storage Service) specifically (can connect to any aws service here)\n",
    "    endpoint_url='https://files.polygon.io', # Base url for the service you want to access\n",
    "    config=Config(signature_version='s3v4'), # Ensures client is using AWS signature Version 4 protocol by prohibiting api requests unless supplied with\n",
    "                                             # a secret key. Used for hashsing\n",
    ")\n",
    "# The previous code is everything needed to accesss the S3 flatfiles, from here you can use commands like list objects or get objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f98c0b-b2b0-4b88-aa88-676ff7f2d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a paginator for listing objects\n",
    "paginator = s3.get_paginator('list_objects_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1ca190-a6e8-4554-9d96-90edf98dea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the appropriate prefix depending on the data you need:\n",
    "# - 'global_crypto' for global cryptocurrency data\n",
    "# - 'global_forex' for global forex data\n",
    "# - 'us_indices' for US indices data\n",
    "# - 'us_options_opra' for US options (OPRA) data\n",
    "# - 'us_stocks_sip' for US stocks (SIP) data\n",
    "def get_daily_polygon_files(start_year, years):\n",
    "    \"\"\"\n",
    "    returns all the s3 files to download\n",
    "\n",
    "    Args:\n",
    "        start_year (int): Year to start historical data pull.\n",
    "        years (int): Amount of years to pull files for.\n",
    "\n",
    "    Returns:\n",
    "        object_keys: A list of files that will be pulled from S3.\n",
    "    \"\"\"\n",
    "    #One liner to make the list of years to pull from. Paginator will recursively get all the files from s3\n",
    "    prefixes = [f'us_stocks_sip/day_aggs_v1/{year}' for year in range(start_year, start_year + years)]\n",
    "    # List objects using the selected prefix\n",
    "    object_keys = []\n",
    "    for prefix in prefixes:\n",
    "        for page in paginator.paginate(Bucket='flatfiles', Prefix=prefix):\n",
    "            for obj in page['Contents']:\n",
    "                object_keys.append(obj['Key'])\n",
    "    return object_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc18496-60ab-47de-be1a-c4f533000833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_data(keys):\n",
    "    \"\"\"\n",
    "    grabs all the csv files stored in keys, unzips them, and concatenates them all in a dataframe\n",
    "\n",
    "\n",
    "    Args:\n",
    "        keys (String[]): list of csv file paths to download from s3\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: dataframe with stock data appended from all days\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for key in tqdm(keys, desc=\"Fetching Stock data\"):\n",
    "        if key.endswith('csv.gz'):\n",
    "            response = s3.get_object(Bucket='flatfiles', Key=key)\n",
    "            df = pd.read_csv(BytesIO(response['Body'].read()), compression = 'gzip')\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db75133-8217-437b-a79e-0670a9372a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Stock data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 503/503 [00:43<00:00, 11.50it/s]\n"
     ]
    }
   ],
   "source": [
    "data = get_daily_data(get_daily_polygon_files(2021, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255f734f-f6bf-42a4-81b6-20586f0ace56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_evaluation(data):\n",
    "    \"\"\"\n",
    "    evaluates the data and prints null values and missing data\n",
    "\n",
    "    Args:\n",
    "        data: input data frame\n",
    "\n",
    "    Returns:\n",
    "        Void\n",
    "    \"\"\"\n",
    "    ticker_counts = data['ticker'].value_counts()\n",
    "    most_common_value = ticker_counts.mode().iloc[0]\n",
    "    num_incomplete_tickers = int((ticker_counts != most_common_value).sum())\n",
    "    incomplete_percentage = (num_incomplete_tickers / ticker_counts.size) * 100\n",
    "    \n",
    "    print(f\"\"\"\n",
    "Amount of null values per column: \\n {data.isnull().sum()} \\n\n",
    "Number of unique tickers: {data['ticker'].nunique()}\n",
    "The mode of the amount of tickers is {most_common_value}\n",
    "The number of incomplete tickers is {num_incomplete_tickers}\n",
    "The percentage of incomplete tickers relative to the mode is {incomplete_percentage:.3f}%\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf361c1f-a492-4b31-99dc-97846c019b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of null values per column: \n",
      " ticker          121\n",
      "volume            0\n",
      "open              0\n",
      "close             0\n",
      "high              0\n",
      "low               0\n",
      "window_start      0\n",
      "transactions      0\n",
      "dtype: int64 \n",
      "\n",
      "Number of unique tickers: 14724\n",
      "The mode of the amount of tickers is 503\n",
      "The number of incomplete tickers is 8078\n",
      "The percentage of incomplete tickers relative to the mode is 54.863%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "data_evaluation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d765823e-99b0-42cb-a02b-fcd1e22a495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#Example inject null values for testing\n",
    "#data.loc[0, 'volume'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2add41d8-83b5-4cbf-98f1-d50f98b44b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_tickers(data):\n",
    "    \n",
    "    #Remove null tickers from ticker list\n",
    "    unique_tickers = data['ticker'].dropna().unique()\n",
    "    tickers_with_null = data[data.isnull().any(axis=1)]['ticker'].dropna().unique().tolist()\n",
    "    valid_tickers = list(set(unique_tickers) - set(tickers_with_null))\n",
    "\n",
    "    #Create new filtered DataFrame and filter further based on mode amount of samples\n",
    "    filtered_null_data = data[data['ticker'].isin(valid_tickers)]\n",
    "    ticker_counts = filtered_null_data['ticker'].value_counts()\n",
    "    most_common_value = ticker_counts.mode().iloc[0]\n",
    "    # Get tickers that don't have the mode number of rows\n",
    "    incomplete_tickers = ticker_counts[ticker_counts != most_common_value].index.tolist()\n",
    "    filtered_final_data = filtered_null_data[filtered_null_data['ticker'].isin(list(set(valid_tickers) - set(incomplete_tickers)))]\n",
    "\n",
    "    #Print null tickers, evaulate final data, and return final df\n",
    "    print(f\"tickers with null: {tickers_with_null}\")\n",
    "    data_evaluation(filtered_final_data)\n",
    "    return filtered_final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef2a076e-e940-499d-bad5-cc4ecf9363f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers with null: []\n",
      "\n",
      "Amount of null values per column: \n",
      " ticker          0\n",
      "volume          0\n",
      "open            0\n",
      "close           0\n",
      "high            0\n",
      "low             0\n",
      "window_start    0\n",
      "transactions    0\n",
      "dtype: int64 \n",
      "\n",
      "Number of unique tickers: 6646\n",
      "The mode of the amount of tickers is 503\n",
      "The number of incomplete tickers is 0\n",
      "The percentage of incomplete tickers relative to the mode is 0.000%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "filtered_data = get_clean_tickers(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ddb91-923b-4bf7-8d58-eaecab39c2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
